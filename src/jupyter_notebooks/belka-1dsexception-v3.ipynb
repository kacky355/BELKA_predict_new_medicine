{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c6e896",
   "metadata": {
    "papermill": {
     "duration": 0.006306,
     "end_time": "2024-06-28T16:03:45.594653",
     "exception": false,
     "start_time": "2024-06-28T16:03:45.588347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1DCNN -> 1DResNet  \n",
    "loss: 0.0104 - avg_precision: 0.7206 - val_loss: 0.0104 - val_avg_precision: 0.7207 - lr: 5.0000e-05  \n",
    "学習時間約8時間半  \n",
    "Polars.DataFrame -> np.ndarrayの変換忘れで落ちかけるも、モデルの重みデータ改修して復旧  \n",
    "LB 0.401\n",
    "\n",
    "1dse+x epoch8 \n",
    "loss: 0.0114 - avg_precision: 0.6824 - val_loss: 0.0136 - val_avg_precision: 0.6122 - lr: 0.0010  \n",
    "LB:0.365 9時間MAX使って８Epochしか回せてないのでlossが落ち切ってなかったっぽい  \n",
    "後半余裕ができ次第lr変えて続きやってもいいかも  \n",
    "もしかしたらスタートのlrはもうちょい高くてもいいかな？\n",
    "\n",
    "0: 293656924 samples\n",
    "1: 1589906 samples\n",
    "\n",
    "SeXc_fold0 : 8Epoch LB:0.410 arc:[8,8,2] 1h47m/epoch\n",
    "\n",
    "SeXc_fold1_01: 2Epoch LB:0.376 archtecture:[4,2,2,2] 1Epoch 1h10m\n",
    "\n",
    "In this notebook we will train a deep learning model using all the data available !\n",
    "* preprocessing : I encoded the smiles of all the train & test set and saved it [here](https://www.kaggle.com/datasets/ahmedelfazouan/belka-enc-dataset) , this may take up to 1 hour on TPU.\n",
    "* Training & Inference : I used a simple 1dcnn model trained on 20 epochs.\n",
    "\n",
    "How to improve :\n",
    "* Try a different architecture : I'm able to get an LB score of 0.604 with minor changes on this architecture.\n",
    "* Try another model like Transformer, or LSTM.\n",
    "* Train for more epochs.\n",
    "* Add more features like a one hot encoding of bb2 or bb3.\n",
    "* And of course ensembling with GBDT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01614f85",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-28T16:03:45.605439Z",
     "iopub.status.busy": "2024-06-28T16:03:45.605108Z",
     "iopub.status.idle": "2024-06-28T16:04:05.241219Z",
     "shell.execute_reply": "2024-06-28T16:04:05.239926Z"
    },
    "papermill": {
     "duration": 19.64485,
     "end_time": "2024-06-28T16:04:05.244057",
     "exception": false,
     "start_time": "2024-06-28T16:03:45.599207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Collecting polars\r\n",
      "  Downloading polars-0.20.31-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: polars\r\n",
      "Successfully installed polars-0.20.31\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Collecting pyarrow\r\n",
      "  Downloading pyarrow-16.1.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/site-packages (from pyarrow) (1.23.5)\r\n",
      "Installing collected packages: pyarrow\r\n",
      "Successfully installed pyarrow-16.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet -q\n",
    "!pip install polars\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5219dc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-28T16:04:05.261532Z",
     "iopub.status.busy": "2024-06-28T16:04:05.260786Z",
     "iopub.status.idle": "2024-06-28T16:04:47.112054Z",
     "shell.execute_reply": "2024-06-28T16:04:47.111271Z"
    },
    "papermill": {
     "duration": 41.862747,
     "end_time": "2024-06-28T16:04:47.114617",
     "exception": false,
     "start_time": "2024-06-28T16:04:05.251870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D0628 16:04:40.160850845      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\n",
      "D0628 16:04:40.160874108      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\n",
      "D0628 16:04:40.160877526      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\n",
      "D0628 16:04:40.160880105      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\n",
      "D0628 16:04:40.160882438      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\n",
      "D0628 16:04:40.160884992      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\n",
      "D0628 16:04:40.160887348      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\n",
      "D0628 16:04:40.160892703      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\n",
      "D0628 16:04:40.160895068      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\n",
      "D0628 16:04:40.160897456      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\n",
      "D0628 16:04:40.160899817      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\n",
      "D0628 16:04:40.160902355      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\n",
      "D0628 16:04:40.160904703      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\n",
      "D0628 16:04:40.160906934      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\n",
      "I0628 16:04:40.161184801      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 59\n",
      "D0628 16:04:40.161198073      14 ev_posix.cc:144]                      Using polling engine: epoll1\n",
      "D0628 16:04:40.161259358      14 dns_resolver_ares.cc:822]             Using ares dns resolver\n",
      "D0628 16:04:40.161660468      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0628 16:04:40.161667598      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0628 16:04:40.161670743      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0628 16:04:40.161673563      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0628 16:04:40.161676644      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0628 16:04:40.161679494      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\n",
      "D0628 16:04:40.161687249      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0628 16:04:40.161704849      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0628 16:04:40.161739930      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0628 16:04:40.161755142      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0628 16:04:40.161758430      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0628 16:04:40.161761527      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0628 16:04:40.161764840      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D0628 16:04:40.161767951      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0628 16:04:40.161771201      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0628 16:04:40.161774906      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\n",
      "I0628 16:04:40.165621043      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0628 16:04:40.202585148      14 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0628 16:04:40.208509208      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-06-28T16:04:40.208491928+00:00\", grpc_status:2}\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, \n",
    "    BatchNormalization, \n",
    "    ReLU, \n",
    "    Add, \n",
    "    Input, \n",
    "    Embedding, \n",
    "    GlobalMaxPooling1D, \n",
    "    GlobalAveragePooling1D,\n",
    "    Reshape,\n",
    "    Multiply,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07fc99a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:04:47.130556Z",
     "iopub.status.busy": "2024-06-28T16:04:47.130089Z",
     "iopub.status.idle": "2024-06-28T16:04:47.135458Z",
     "shell.execute_reply": "2024-06-28T16:04:47.134802Z"
    },
    "papermill": {
     "duration": 0.01533,
     "end_time": "2024-06-28T16:04:47.137133",
     "exception": false,
     "start_time": "2024-06-28T16:04:47.121803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEBUG = False\n",
    "    PREPROCESS = False\n",
    "    EPOCHS = 7\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-4\n",
    "    WD = 0.05\n",
    "    \n",
    "    N_ROWS = None\n",
    "    \n",
    "    NBR_FOLDS = 15\n",
    "    SELECTED_FOLDS = [1]\n",
    "    \n",
    "    ON_TPU = False\n",
    "    \n",
    "    if DEBUG:\n",
    "        EPOCHS = 3\n",
    "        BATCH_SIZE = 1024\n",
    "        NBR_FOLDS = 5\n",
    "        N_ROWS = 100_000\n",
    "    \n",
    "    CHANNELS = 256\n",
    "    EMB_SIZE = 128\n",
    "    \n",
    "    \n",
    "    SEED = 2024\n",
    "    \n",
    "    BASE_DIR = '/kaggle/working/'\n",
    "    LOG_DIR = os.path.join(BASE_DIR, 'logs')\n",
    "    ADD_LEARN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c7af23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:04:47.151858Z",
     "iopub.status.busy": "2024-06-28T16:04:47.151635Z",
     "iopub.status.idle": "2024-06-28T16:04:48.252509Z",
     "shell.execute_reply": "2024-06-28T16:04:48.251241Z"
    },
    "papermill": {
     "duration": 1.111311,
     "end_time": "2024-06-28T16:04:48.255122",
     "exception": false,
     "start_time": "2024-06-28T16:04:47.143811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%mkdir {CFG.LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626081a9",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-28T16:04:48.270764Z",
     "iopub.status.busy": "2024-06-28T16:04:48.270499Z",
     "iopub.status.idle": "2024-06-28T16:04:48.275796Z",
     "shell.execute_reply": "2024-06-28T16:04:48.275067Z"
    },
    "papermill": {
     "duration": 0.015199,
     "end_time": "2024-06-28T16:04:48.277584",
     "exception": false,
     "start_time": "2024-06-28T16:04:48.262385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1b739c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:04:48.293051Z",
     "iopub.status.busy": "2024-06-28T16:04:48.292825Z",
     "iopub.status.idle": "2024-06-28T16:04:56.864266Z",
     "shell.execute_reply": "2024-06-28T16:04:56.863478Z"
    },
    "papermill": {
     "duration": 8.58368,
     "end_time": "2024-06-28T16:04:56.868376",
     "exception": false,
     "start_time": "2024-06-28T16:04:48.284696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
      "Running on TPU\n",
      "ON_TPU : True\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU\")\n",
    "    CFG.ON_TPU = True\n",
    "    print(f'ON_TPU : {CFG.ON_TPU}')    \n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "except tf.errors.NotFoundError:\n",
    "    print(\"Not on TPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e490489",
   "metadata": {
    "papermill": {
     "duration": 0.007689,
     "end_time": "2024-06-28T16:04:56.884281",
     "exception": false,
     "start_time": "2024-06-28T16:04:56.876592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84be1fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:04:56.900209Z",
     "iopub.status.busy": "2024-06-28T16:04:56.899920Z",
     "iopub.status.idle": "2024-06-28T16:05:04.263520Z",
     "shell.execute_reply": "2024-06-28T16:05:04.262624Z"
    },
    "papermill": {
     "duration": 7.374378,
     "end_time": "2024-06-28T16:05:04.266019",
     "exception": false,
     "start_time": "2024-06-28T16:04:56.891641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.PREPROCESS:\n",
    "    enc = {'l': 1, 'y': 2, '@': 3, '3': 4, 'H': 5, 'S': 6, 'F': 7, 'C': 8, 'r': 9, 's': 10, '/': 11, 'c': 12, 'o': 13,\n",
    "           '+': 14, 'I': 15, '5': 16, '(': 17, '2': 18, ')': 19, '9': 20, 'i': 21, '#': 22, '6': 23, '8': 24, '4': 25, '=': 26,\n",
    "           '1': 27, 'O': 28, '[': 29, 'D': 30, 'B': 31, ']': 32, 'N': 33, '7': 34, 'n': 35, '-': 36}\n",
    "    train_raw = pd.read_parquet('/kaggle/input/leash-BELKA/train.parquet')\n",
    "    smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values\n",
    "    assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n",
    "    assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n",
    "    def encode_smile(smile):\n",
    "        tmp = [enc[i] for i in smile]\n",
    "        tmp = tmp + [0]*(142-len(tmp))\n",
    "        return np.array(tmp).astype(np.uint8)\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    train = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n",
    "    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "    train.to_parquet('train_enc.parquet')\n",
    "\n",
    "    test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "    smiles = test_raw['molecule_smiles'].values\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    test = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n",
    "    test.to_parquet('test_enc.parquet')\n",
    "\n",
    "else:\n",
    "    if CFG.DEBUG:\n",
    "        train = pl.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet', n_rows=CFG.N_ROWS)\n",
    "        test = pl.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet', n_rows=CFG.N_ROWS)\n",
    "    else:\n",
    "        train = pl.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet')\n",
    "        test = pl.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931a1d9",
   "metadata": {
    "papermill": {
     "duration": 0.007563,
     "end_time": "2024-06-28T16:05:04.282253",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.274690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d30c28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.298275Z",
     "iopub.status.busy": "2024-06-28T16:05:04.297985Z",
     "iopub.status.idle": "2024-06-28T16:05:04.302814Z",
     "shell.execute_reply": "2024-06-28T16:05:04.302176Z"
    },
    "papermill": {
     "duration": 0.014981,
     "end_time": "2024-06-28T16:05:04.304335",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.289354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelArgs:\n",
    "    input_dim = CFG.EMB_SIZE\n",
    "    channels: int = CFG.CHANNELS \n",
    "    conv_kernel_size: int = 3\n",
    "    seq_length: int = 142\n",
    "    num_layers: list = [4,2,2,2]\n",
    "    dropout_rate: float = 0.2\n",
    "    num_classes: int = 3\n",
    "    vocab_size: int = 37\n",
    "    activation: str = 'silu'\n",
    "    se_reduction: int = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "902a7250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.320181Z",
     "iopub.status.busy": "2024-06-28T16:05:04.319890Z",
     "iopub.status.idle": "2024-06-28T16:05:04.325524Z",
     "shell.execute_reply": "2024-06-28T16:05:04.324973Z"
    },
    "papermill": {
     "duration": 0.015337,
     "end_time": "2024-06-28T16:05:04.327064",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.311727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvSiluBN(layers.Layer):\n",
    "    def __init__(self, out_size:int,kernel:int=3, strides:int=1, act:bool=True):\n",
    "        super().__init__()\n",
    "        self.act = act\n",
    "        self.bn= layers.BatchNormalization()\n",
    "        initializer = keras.initializers.HeNormal(CFG.SEED)\n",
    "        self.conv = layers.SeparableConv1D(out_size, kernel, strides=strides, padding='same',depthwise_initializer=initializer, pointwise_initializer=initializer)\n",
    "        \n",
    "    def call(self, x):\n",
    "        if self.act:\n",
    "            x = keras.activations.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3607f863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.342966Z",
     "iopub.status.busy": "2024-06-28T16:05:04.342733Z",
     "iopub.status.idle": "2024-06-28T16:05:04.348769Z",
     "shell.execute_reply": "2024-06-28T16:05:04.348090Z"
    },
    "papermill": {
     "duration": 0.016212,
     "end_time": "2024-06-28T16:05:04.350607",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.334395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XceptionLayer(layers.Layer):\n",
    "    def __init__(self,  out_size_1:int, out_size_2=None,strides:int=1, act:bool=True, pool:bool=False):\n",
    "        super().__init__()\n",
    "        if out_size_2 is None:\n",
    "            out_size_2 = out_size_1\n",
    "        \n",
    "        self.conv1 = ConvSiluBN(out_size_1, act=act)\n",
    "        self.conv2 = ConvSiluBN(out_size_2)\n",
    "        if pool:\n",
    "            self.fc = layers.MaxPool1D(pool_size=3, strides=strides, padding='same')\n",
    "        else:\n",
    "            self.fc = ConvSiluBN(out_size_2, strides=strides)\n",
    "        self.se = SELayer(out_size_2)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.se(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da33c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.366801Z",
     "iopub.status.busy": "2024-06-28T16:05:04.366552Z",
     "iopub.status.idle": "2024-06-28T16:05:04.372355Z",
     "shell.execute_reply": "2024-06-28T16:05:04.371637Z"
    },
    "papermill": {
     "duration": 0.016352,
     "end_time": "2024-06-28T16:05:04.374107",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.357755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SELayer(layers.Layer):\n",
    "    def __init__(self,input_size:int , reduction:int=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = layers.GlobalAveragePooling1D(keepdims=True)\n",
    "        self.dense1 = layers.Dense(\n",
    "            input_size // reduction, \n",
    "            activation='silu',\n",
    "            use_bias = False\n",
    "        )\n",
    "        self.dense2 = layers.Dense(\n",
    "            input_size, \n",
    "            activation='sigmoid',\n",
    "            use_bias = False\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.dense1(y)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68bbcdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.389682Z",
     "iopub.status.busy": "2024-06-28T16:05:04.389425Z",
     "iopub.status.idle": "2024-06-28T16:05:04.395692Z",
     "shell.execute_reply": "2024-06-28T16:05:04.395003Z"
    },
    "papermill": {
     "duration": 0.015988,
     "end_time": "2024-06-28T16:05:04.397403",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.381415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualLayer(layers.Layer):\n",
    "    def __init__(self, input_size:int, out_size:int, strides:int=1, pool:bool=False):\n",
    "        super().__init__()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.xcp = XceptionLayer(out_size,strides=strides,pool=pool)\n",
    "        self.in_eq_out = input_size == out_size\n",
    "        if not self.in_eq_out :\n",
    "            self.conv = layers.Conv1D(out_size,1, strides=strides, padding='same', kernel_initializer='he_normal')\n",
    "        self.add = layers.Add()\n",
    "            \n",
    "    \n",
    "    def call(self, x):\n",
    "        res = x\n",
    "        if not self.in_eq_out:\n",
    "            res = self.conv(res)\n",
    "        \n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = self.xcp(x)\n",
    "        x = self.add([x, res])\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a78b386d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.414431Z",
     "iopub.status.busy": "2024-06-28T16:05:04.414013Z",
     "iopub.status.idle": "2024-06-28T16:05:04.418940Z",
     "shell.execute_reply": "2024-06-28T16:05:04.418272Z"
    },
    "papermill": {
     "duration": 0.015334,
     "end_time": "2024-06-28T16:05:04.420782",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.405448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self,in_size, out_size, num_layer, strides):\n",
    "        super().__init__()\n",
    "        self.layers = [ResidualLayer(in_size,in_size) for _ in range(num_layer-1)]\n",
    "        self.last_layer = ResidualLayer(in_size, out_size, strides=strides, pool=True)\n",
    "    \n",
    "    def call(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dee938d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:04.436584Z",
     "iopub.status.busy": "2024-06-28T16:05:04.436324Z",
     "iopub.status.idle": "2024-06-28T16:05:14.039503Z",
     "shell.execute_reply": "2024-06-28T16:05:14.038393Z"
    },
    "papermill": {
     "duration": 9.613831,
     "end_time": "2024-06-28T16:05:14.041665",
     "exception": false,
     "start_time": "2024-06-28T16:05:04.427834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 142)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 142, 128)          4736      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 142, 256)          33024     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 142, 256)         1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  (None, 71, 512)          1198848   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 71, 512)           0         \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  (None, 71, 768)          2294784   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 71, 768)           0         \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  (None, 36, 1024)         4632832   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 36, 1024)          0         \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  (None, 36, 1280)         7790080   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 36, 1280)          0         \n",
      "                                                                 \n",
      " layer_normalization_10 (Lay  (None, 36, 1280)         2560      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 1280)             0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1024)              1311744   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,058,627\n",
      "Trainable params: 18,027,395\n",
      "Non-trainable params: 31,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_tpu_model(args: ModelArgs):\n",
    "    with strategy.scope():\n",
    "        inputs = keras.Input(shape=(args.seq_length,), dtype='int32')\n",
    "        x = layers.Embedding(input_dim=args.vocab_size, output_dim=args.input_dim, input_length=args.seq_length, mask_zero = True)(inputs)\n",
    "        x = layers.Conv1D(args.channels, 1,padding='same',activation='relu', kernel_initializer='he_normal')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        for i, layer_size in enumerate(args.num_layers, 1):\n",
    "            strides = 2\n",
    "            if i % 2 == 0:\n",
    "                strides = 1\n",
    "            x = ResidualBlock(args.channels*i,args.channels*(i+1), layer_size, strides)(x)\n",
    "            x = layers.Dropout(0.1)(x)\n",
    "\n",
    "        x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
    "\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "\n",
    "        outputs = Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=CFG.LR, weight_decay = CFG.WD)\n",
    "        loss = 'binary_crossentropy'\n",
    "        weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n",
    "        model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        weighted_metrics=weighted_metrics,\n",
    "        )\n",
    "        return model\n",
    "\n",
    "model = make_tpu_model(ModelArgs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c44a4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:14.064437Z",
     "iopub.status.busy": "2024-06-28T16:05:14.064092Z",
     "iopub.status.idle": "2024-06-28T16:05:23.883680Z",
     "shell.execute_reply": "2024-06-28T16:05:23.882340Z"
    },
    "papermill": {
     "duration": 9.833769,
     "end_time": "2024-06-28T16:05:23.886199",
     "exception": false,
     "start_time": "2024-06-28T16:05:14.052430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.ADD_LEARN:\n",
    "    model.load_weights('/kaggle/input/xse_v3/tensorflow2/fold1_01/1/model-1_SeXc_01.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6ddba",
   "metadata": {
    "papermill": {
     "duration": 0.01033,
     "end_time": "2024-06-28T16:05:23.907231",
     "exception": false,
     "start_time": "2024-06-28T16:05:23.896901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602b89c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:05:23.929692Z",
     "iopub.status.busy": "2024-06-28T16:05:23.929345Z",
     "iopub.status.idle": "2024-06-29T00:37:40.667693Z",
     "shell.execute_reply": "2024-06-29T00:37:40.666186Z"
    },
    "papermill": {
     "duration": 30737.03308,
     "end_time": "2024-06-29T00:37:40.950584",
     "exception": false,
     "start_time": "2024-06-28T16:05:23.917504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 16:07:24.632728: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_396/ReadVariableOp.\n",
      "2024-06-28 16:07:25.622975: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_396/ReadVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22426/22426 [==============================] - ETA: 0s - loss: 0.0116 - avg_precision: 0.6723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 17:19:03.692814: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n",
      "2024-06-28 17:19:03.912206: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22426/22426 [==============================] - 4434s 194ms/step - loss: 0.0116 - avg_precision: 0.6723 - val_loss: 0.0117 - val_avg_precision: 0.6870 - lr: 1.0000e-04\n",
      "Epoch 2/7\n",
      "22426/22426 [==============================] - 4302s 192ms/step - loss: 0.0112 - avg_precision: 0.6886 - val_loss: 0.0110 - val_avg_precision: 0.6980 - lr: 1.0000e-04\n",
      "Epoch 3/7\n",
      "22426/22426 [==============================] - 4351s 194ms/step - loss: 0.0110 - avg_precision: 0.6983 - val_loss: 0.0110 - val_avg_precision: 0.7018 - lr: 1.0000e-04\n",
      "Epoch 4/7\n",
      "22426/22426 [==============================] - 4349s 194ms/step - loss: 0.0108 - avg_precision: 0.7053 - val_loss: 0.0107 - val_avg_precision: 0.7098 - lr: 1.0000e-04\n",
      "Epoch 5/7\n",
      "22426/22426 [==============================] - 4361s 194ms/step - loss: 0.0107 - avg_precision: 0.7106 - val_loss: 0.0107 - val_avg_precision: 0.7119 - lr: 1.0000e-04\n",
      "Epoch 6/7\n",
      "22426/22426 [==============================] - 4344s 194ms/step - loss: 0.0106 - avg_precision: 0.7146 - val_loss: 0.0107 - val_avg_precision: 0.7111 - lr: 1.0000e-04\n",
      "Epoch 7/7\n",
      "22426/22426 [==============================] - 4355s 194ms/step - loss: 0.0105 - avg_precision: 0.7180 - val_loss: 0.0107 - val_avg_precision: 0.7155 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 00:35:17.546516: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-29 00:35:17.728067: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 101s 110ms/step\n",
      "fold : 1 CV score = 0.7169305243464026\n",
      "205/205 [==============================] - 29s 139ms/step\n",
      "train_finish\n"
     ]
    }
   ],
   "source": [
    "FEATURES = [f'enc{i}' for i in range(142)]\n",
    "TARGETS = ['bind1', 'bind2', 'bind3']\n",
    "skf = StratifiedKFold(n_splits = CFG.NBR_FOLDS, shuffle = True, random_state = 42)\n",
    "fold_indexes = []\n",
    "all_preds = []\n",
    "for fold,(train_idx, valid_idx) in enumerate(skf.split(np.arange(len(train)), train[TARGETS].sum_horizontal())):\n",
    "    \n",
    "    if fold not in CFG.SELECTED_FOLDS:\n",
    "        fold_indexes.append(valid_idx)\n",
    "        continue;\n",
    "    \n",
    "    X_train = train[train_idx, FEATURES].to_numpy()\n",
    "    y_train = train[train_idx, TARGETS].to_numpy()\n",
    "    X_val = train[valid_idx, FEATURES].to_numpy()\n",
    "    y_val = train[valid_idx, TARGETS].to_numpy()\n",
    "\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=CFG.LOG_DIR)\n",
    "    es = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\", mode='min', verbose=1)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=f\"model-{fold}.h5\",\n",
    "                                                        save_best_only=True, save_weights_only=True,\n",
    "                                                    mode='min')\n",
    "    reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1)\n",
    "#     model = my_model()\n",
    "    history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=CFG.EPOCHS,\n",
    "            callbacks=[checkpoint, reduce_lr_loss, es, tensorboard_callback],\n",
    "            batch_size=CFG.BATCH_SIZE,\n",
    "            verbose=1,\n",
    "        )\n",
    "    model.load_weights(f\"model-{fold}.h5\")\n",
    "    oof = model.predict(X_val, batch_size = 2*CFG.BATCH_SIZE)\n",
    "    print('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n",
    "    \n",
    "    preds = model.predict(test.to_numpy(), batch_size = 2*CFG.BATCH_SIZE)\n",
    "    all_preds.append(preds)\n",
    "\n",
    "print('train_finish')\n",
    "preds = np.mean(all_preds, 0)\n",
    "\n",
    "# kf = pd.DataFrame(fold_indexes)\n",
    "# kf.to_csv('/kaggle/working/skf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f226b7f",
   "metadata": {
    "papermill": {
     "duration": 9.294061,
     "end_time": "2024-06-29T00:37:59.558246",
     "exception": false,
     "start_time": "2024-06-29T00:37:50.264185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4033184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T00:38:18.544098Z",
     "iopub.status.busy": "2024-06-29T00:38:18.543094Z",
     "iopub.status.idle": "2024-06-29T00:38:25.764858Z",
     "shell.execute_reply": "2024-06-29T00:38:25.762924Z"
    },
    "papermill": {
     "duration": 16.362686,
     "end_time": "2024-06-29T00:38:25.767474",
     "exception": false,
     "start_time": "2024-06-29T00:38:09.404788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "tst['binds'] = 0\n",
    "tst.loc[tst['protein_name']=='BRD4', 'binds'] = preds[(tst['protein_name']=='BRD4').values, 0]\n",
    "tst.loc[tst['protein_name']=='HSA', 'binds'] = preds[(tst['protein_name']=='HSA').values, 1]\n",
    "tst.loc[tst['protein_name']=='sEH', 'binds'] = preds[(tst['protein_name']=='sEH').values, 2]\n",
    "tst[['id', 'binds']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4914065,
     "sourceId": 8275617,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 58720,
     "sourceId": 70337,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30514,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30902.994284,
   "end_time": "2024-06-29T00:38:46.208022",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-28T16:03:43.213738",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
