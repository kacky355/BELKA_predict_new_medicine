{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"},{"sourceId":8275617,"sourceType":"datasetVersion","datasetId":4914065}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T10:18:35.875759Z","iopub.execute_input":"2024-06-10T10:18:35.876201Z","iopub.status.idle":"2024-06-10T10:18:37.000856Z","shell.execute_reply.started":"2024-06-10T10:18:35.876163Z","shell.execute_reply":"2024-06-10T10:18:36.999729Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install polars \n!pip install einops","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:18:37.003111Z","iopub.execute_input":"2024-06-10T10:18:37.003758Z","iopub.status.idle":"2024-06-10T10:19:03.109470Z","shell.execute_reply.started":"2024-06-10T10:18:37.003692Z","shell.execute_reply":"2024-06-10T10:19:03.107786Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport os\nimport pickle\nimport random\nimport joblib\nimport math\n\nimport numpy as np\nimport polars as pl\nimport pandas as pd\nimport pyarrow\n\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import average_precision_score as APS\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers , Model\n\nfrom einops import rearrange, repeat","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:03.111778Z","iopub.execute_input":"2024-06-10T10:19:03.112304Z","iopub.status.idle":"2024-06-10T10:19:13.019971Z","shell.execute_reply.started":"2024-06-10T10:19:03.112250Z","shell.execute_reply":"2024-06-10T10:19:13.018990Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    DEBUG = True\n    PREPROCESS = False\n    EPOCHS = 8\n    BATCH_SIZE = 512\n    LR = 1e-3\n    WD = 0.05\n    \n    N_ROWS = None\n    \n    NBR_FOLDS = 15\n    SELECTED_FOLDS = [0]\n    \n    ON_TPU = False\n    \n    if DEBUG:\n        EPOCHS = 3\n        BATCH_SIZE = 512\n        NBR_FOLDS = 5\n        N_ROWS = 1_000_000\n    \n    CHANNELS = 128\n    EMB_SIZE = 64\n    \n    \n    SEED = 2024\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:13.022197Z","iopub.execute_input":"2024-06-10T10:19:13.022851Z","iopub.status.idle":"2024-06-10T10:19:13.030848Z","shell.execute_reply.started":"2024-06-10T10:19:13.022818Z","shell.execute_reply":"2024-06-10T10:19:13.029571Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seeds(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n\nset_seeds(seed=CFG.SEED)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:13.032256Z","iopub.execute_input":"2024-06-10T10:19:13.032811Z","iopub.status.idle":"2024-06-10T10:19:13.051769Z","shell.execute_reply.started":"2024-06-10T10:19:13.032766Z","shell.execute_reply":"2024-06-10T10:19:13.050514Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n    tf.config.experimental_connect_to_cluster(tpu)\n    # This is the TPU initialization code that has to be at the beginning.\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\n    CFG.ON_TPU = True\n    print(f\"Running on TPU, ON_TPU ={CFG.ON_TPU}\")\n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\nexcept tf.errors.NotFoundError:\n    print(\"Not on TPU\")","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:13.053156Z","iopub.execute_input":"2024-06-10T10:19:13.053539Z","iopub.status.idle":"2024-06-10T10:19:13.313665Z","shell.execute_reply.started":"2024-06-10T10:19:13.053507Z","shell.execute_reply":"2024-06-10T10:19:13.312452Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"if CFG.PREPROCESS:\n    enc = {'l': 1, 'y': 2, '@': 3, '3': 4, 'H': 5, 'S': 6, 'F': 7, 'C': 8, 'r': 9, 's': 10, '/': 11, 'c': 12, 'o': 13,\n           '+': 14, 'I': 15, '5': 16, '(': 17, '2': 18, ')': 19, '9': 20, 'i': 21, '#': 22, '6': 23, '8': 24, '4': 25, '=': 26,\n           '1': 27, 'O': 28, '[': 29, 'D': 30, 'B': 31, ']': 32, 'N': 33, '7': 34, 'n': 35, '-': 36}\n    train_raw = pd.read_parquet('/kaggle/input/leash-BELKA/train.parquet')\n    smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values\n    assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n    assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n    def encode_smile(smile):\n        tmp = [enc[i] for i in smile]\n        tmp = tmp + [0]*(142-len(tmp))\n        return np.array(tmp).astype(np.uint8)\n\n    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n    smiles_enc = np.stack(smiles_enc)\n    train = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n    train.to_parquet('train_enc.parquet')\n\n    test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n    smiles = test_raw['molecule_smiles'].values\n\n    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n    smiles_enc = np.stack(smiles_enc)\n    test = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n    test.to_parquet('test_enc.parquet')\n\nelse:\n    if CFG.DEBUG:\n        train = pl.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet', n_rows=CFG.N_ROWS)\n        test = pl.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet', n_rows=CFG.N_ROWS)\n    else:\n        train = pl.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet')\n        test = pl.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:13.315415Z","iopub.execute_input":"2024-06-10T10:19:13.315907Z","iopub.status.idle":"2024-06-10T10:19:14.095307Z","shell.execute_reply.started":"2024-06-10T10:19:13.315858Z","shell.execute_reply":"2024-06-10T10:19:14.094313Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Make Dataset","metadata":{}},{"cell_type":"code","source":"FEATURES = [f'enc{i}' for i in range(142)]\nTARGETS = ['bind1', 'bind2', 'bind3']\nskf = StratifiedKFold(n_splits = CFG.NBR_FOLDS, shuffle = True, random_state = 42)\n\ntrain_idx, valid_idx = next(iter(skf.split(np.arange(len(train)), train[TARGETS].sum_horizontal())))\n    \nX_train = train[train_idx, FEATURES].to_numpy()\ny_train = train[train_idx, TARGETS].to_numpy()\nX_val = train[valid_idx, FEATURES].to_numpy()\ny_val = train[valid_idx, TARGETS].to_numpy()\nprint('data loaded')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.097012Z","iopub.execute_input":"2024-06-10T10:19:14.097484Z","iopub.status.idle":"2024-06-10T10:19:14.152641Z","shell.execute_reply.started":"2024-06-10T10:19:14.097453Z","shell.execute_reply":"2024-06-10T10:19:14.151503Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Make Model","metadata":{}},{"cell_type":"code","source":"class ModelArgs:\n    model_input_dim = CFG.EMB_SIZE\n    model_states: int = 64\n    model_internal_dim: int = CFG.CHANNELS \n    conv_kernel_size: int = 3\n    delta_t_rank = math.ceil(model_input_dim / 16)\n    delta_t_min: float = 0.001\n    delta_t_max: float = 0.1\n    delta_t_scale: float = 0.1\n    delta_t_init_floor: float = 1e-4\n    layer_id: int = -1\n    seq_length: int = 142\n    num_layers: int = 4\n    dropout_rate: float = 0.2\n    use_lm_head: float = False\n    num_classes: int = 3\n    vocab_size: int = 37\n    final_activation = 'sigmoid'\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.153998Z","iopub.execute_input":"2024-06-10T10:19:14.154335Z","iopub.status.idle":"2024-06-10T10:19:14.161158Z","shell.execute_reply.started":"2024-06-10T10:19:14.154306Z","shell.execute_reply":"2024-06-10T10:19:14.159951Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RMSNorm(layers.Layer):\n    def __init__(self, d_model: int, eps: float=1e-5, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.eps = eps\n        self.weight = tf.Variable(np.ones(d_model), dtype=tf.float32, trainable=True)\n\n    def call(self, x):\n        x = tf.math.reduce_mean(tf.math.pow(x, 2), axis=-1, keepdims=True)\n        output = x * tf.math.rsqrt(x + self.eps) * self.weight\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.166291Z","iopub.execute_input":"2024-06-10T10:19:14.166729Z","iopub.status.idle":"2024-06-10T10:19:14.173900Z","shell.execute_reply.started":"2024-06-10T10:19:14.166687Z","shell.execute_reply":"2024-06-10T10:19:14.172803Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def selective_scan(u, delta, A, B, C, D):\n    dA = tf.einsum('bld,dn->bldn', delta, A)\n    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n    \n    dA_cumsum = tf.pad(dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])\n    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)\n    dA_cumsum = tf.exp(dA_cumsum)\n    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])\n    \n    x = dB_u * dA_cumsum\n    x = tf.math.cumsum(x, axis=1) / (dA_cumsum + 1e-12)\n    \n    y = tf.einsum('bldn,bln->bld', x, C)\n    \n    return y + u * D","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.175017Z","iopub.execute_input":"2024-06-10T10:19:14.175350Z","iopub.status.idle":"2024-06-10T10:19:14.186265Z","shell.execute_reply.started":"2024-06-10T10:19:14.175323Z","shell.execute_reply":"2024-06-10T10:19:14.185176Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MambaLayer(layers.Layer):\n    def __init__(self, model_args: ModelArgs, *args, **kwargs):\n        super().__init__()\n        self.args = model_args \n        \n        self.in_projection = layers.Dense(\n            self.args.model_internal_dim * 2,\n            input_shape = (self.args.model_input_dim,),\n            use_bias  = False\n        )\n        self.conv1D = layers.Conv1D(\n            filters=self.args.model_internal_dim,\n            kernel_size = self.args.conv_kernel_size,\n            padding = 'same',\n            use_bias = True,\n            groups = self.args.model_internal_dim,\n            data_format = 'channels_last',\n            activation = 'silu'\n        )\n        \n        \n        A = repeat(\n            tf.range(1, self.args.model_states +1, dtype=tf.float32),\n            'n -> d n', d=self.args.model_internal_dim)\n        self.A_log = tf.Variable(tf.math.log(A), trainable=False, dtype=tf.float32)\n        \n        self.D = tf.Variable(tf.ones(self.args.model_internal_dim), dtype=tf.float32)\n        \n        self.x_projection = layers.Dense(\n            self.args.delta_t_rank + self.args.model_states *2,\n            use_bias=False\n        )\n        \n        self.delta_projection = layers.Dense(\n            self.args.model_internal_dim,\n            input_shape=(self.args.delta_t_rank,),\n            use_bias=True\n        )\n        \n        self.out_projection = layers.Dense(\n            self.args.model_input_dim,\n            input_shape = (self.args.model_internal_dim, ),\n            use_bias = False\n        )\n    \n    \n    def call(self, x):\n        batch_size, seq_len, channels = x.shape\n        \n        x_res = self.in_projection(x)\n        x, res = tf.split(\n            x_res,\n            [self.args.model_internal_dim, self.args.model_internal_dim],\n            axis = -1\n        )\n        \n        x = self.conv1D(x)\n        y = self.ssm(x)\n        y = y * tf.nn.swish(res)\n        return self.out_projection(y)\n    \n    def ssm(self, x):\n        d_in,n = self.A_log.shape\n        \n        A = -tf.exp(tf.cast(self.A_log,tf.float32))\n        D = tf.cast(self.D, tf.float32)\n        \n        x_dbl = self.x_projection(x)\n        delta, B, C = tf.split(\n            x_dbl,\n            [self.args.delta_t_rank, n, n],\n            axis=-1,\n        )\n        \n        delta = tf.nn.softplus(\n            self.delta_projection(delta)\n        )\n        \n        return selective_scan(x, delta, A, B, C, D)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.187788Z","iopub.execute_input":"2024-06-10T10:19:14.188187Z","iopub.status.idle":"2024-06-10T10:19:14.204526Z","shell.execute_reply.started":"2024-06-10T10:19:14.188157Z","shell.execute_reply":"2024-06-10T10:19:14.203240Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DemoLayer(layers.Layer):\n    def __init__(self, model_args, *args, **kwargs):\n        super().__init__()\n        self.args = model_args\n        self.conv1D = layers.Conv1D(\n            filters=self.args.model_input_dim,\n            kernel_size = self.args.conv_kernel_size,\n            padding = 'same',\n            use_bias = True,\n            groups = self.args.model_internal_dim,\n            data_format = 'channels_last',\n            activation = 'silu'\n        )\n    \n    def call(self, x):\n        x = self.conv1D(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResidualLayer(layers.Layer):\n    def __init__(self, model_args: ModelArgs, *args, **kwargs):\n        super().__init__()\n        self.args = model_args\n        self.norm = layers.LayerNormalization(epsilon=1e-5)\n#         self.demo = DemoLayer(self.args)\n        self.mamba = MambaLayer(self.args)\n    \n    def call(self, x):\n        res = x\n        x = self.norm(x)\n#         x = self.demo(x)\n        x = self.mamba(x)\n        x = x + res\n        return x        ","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.206077Z","iopub.execute_input":"2024-06-10T10:19:14.206788Z","iopub.status.idle":"2024-06-10T10:19:14.222407Z","shell.execute_reply.started":"2024-06-10T10:19:14.206740Z","shell.execute_reply":"2024-06-10T10:19:14.221294Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_model(args: ModelArgs):\n\n    inputs = layers.Input(shape=(args.seq_length,), dtype='int32')\n    x = layers.Embedding(input_dim=args.vocab_size, output_dim=args.model_input_dim, input_length=args.seq_length, mask_zero = True)(inputs)\n    for i in range(args.num_layers):\n        x = ResidualLayer(args)(x)\n        x = layers.Dropout(args.dropout_rate)(x)\n\n    x = layers.LayerNormalization(epsilon=1e-5)(x)\n\n    x = layers.GlobalMaxPooling1D()(x)\n\n    x = layers.Dense(1024, activation='relu')(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.1)(x)\n\n    outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n\n    model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n    \n    loss = 'binary_crossentropy'\n    optimizer = tf.keras.optimizers.Adam(learning_rate=CFG.LR, weight_decay = CFG.WD)\n    weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n\n    model.compile(\n        loss=loss,\n        optimizer=optimizer,\n        weighted_metrics=weighted_metrics,\n        )\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.223669Z","iopub.execute_input":"2024-06-10T10:19:14.224056Z","iopub.status.idle":"2024-06-10T10:19:14.233934Z","shell.execute_reply.started":"2024-06-10T10:19:14.224026Z","shell.execute_reply":"2024-06-10T10:19:14.232904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_tpu_model(args: ModelArgs):\n    with strategy.scope():\n        inputs = layers.Input(shape=(args.seq_length,), dtype='int32')\n        x = layers.Embedding(input_dim=args.vocab_size, output_dim=args.model_input_dim, input_length=args.seq_length, mask_zero = True)(inputs)\n        for i in range(args.num_layers):\n            x = ResidualLayer(args)(x)\n            x = layers.Dropout(args.dropout_rate)(x)\n\n        x = layers.LayerNormalization(epsilon=1e-5)(x)\n\n        x = layers.GlobalMaxPooling1D()(x)\n\n        x = layers.Dense(1024, activation='relu')(x)\n        x = layers.Dropout(0.1)(x)\n        x = layers.Dense(512, activation='relu')(x)\n        x = layers.Dropout(0.1)(x)\n        x = layers.Dense(512, activation='relu')(x)\n        x = layers.Dropout(0.1)(x)\n\n        outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n\n        model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n        loss = 'binary_crossentropy'\n        optimizer = tf.keras.optimizers.Adam(learning_rate=CFG.LR, weight_decay = CFG.WD)\n        weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n\n        model.compile(\n            loss=loss,\n            optimizer=optimizer,\n            weighted_metrics=weighted_metrics,\n            )\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.235103Z","iopub.execute_input":"2024-06-10T10:19:14.235433Z","iopub.status.idle":"2024-06-10T10:19:14.249592Z","shell.execute_reply.started":"2024-06-10T10:19:14.235405Z","shell.execute_reply":"2024-06-10T10:19:14.248426Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\", mode='min', verbose=1)\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=f\"mamba_model.weights.h5\",\n                                                    save_best_only=True, save_weights_only=True,\n                                                mode='min')\nreduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1)\nmodel = make_tpu_model(ModelArgs) if CFG.ON_TPU else make_model(ModelArgs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:14.251159Z","iopub.execute_input":"2024-06-10T10:19:14.251543Z","iopub.status.idle":"2024-06-10T10:19:15.344402Z","shell.execute_reply.started":"2024-06-10T10:19:14.251512Z","shell.execute_reply":"2024-06-10T10:19:15.343180Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('train start')\nhistory = model.fit(\n            X_train, y_train,\n            validation_data=(X_val, y_val),\n            epochs=CFG.EPOCHS,\n            callbacks=[checkpoint, reduce_lr_loss, es],\n            batch_size=CFG.BATCH_SIZE,\n            verbose=1,\n        )\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T10:19:15.346061Z","iopub.execute_input":"2024-06-10T10:19:15.347003Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"model.load_weights(f\"mamba_model.weights.h5\")\n    \nprint('prediction start')\noof = model.predict(X_val, batch_size = 2*CFG.BATCH_SIZE)\nprint('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n\npreds = model.predict(test.to_numpy(), batch_size = 2*CFG.BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save output","metadata":{}},{"cell_type":"code","source":"val = pl.DataFrame()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tst = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\ntst['binds'] = 0\ntst.loc[tst['protein_name']=='BRD4', 'binds'] = preds[(tst['protein_name']=='BRD4').values, 0]\ntst.loc[tst['protein_name']=='HSA', 'binds'] = preds[(tst['protein_name']=='HSA').values, 1]\ntst.loc[tst['protein_name']=='sEH', 'binds'] = preds[(tst['protein_name']=='sEH').values, 2]\ntst[['id', 'binds']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}